This project was created to better understand the concepts of self attention, mult-head attention and the overall working of transformers
It is inspired from the nanogpt project (https://github.com/karpathy/nanoGPT)
